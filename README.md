#Demo

i am checking my git here for use get my hf spaces.


checkout the diff values.


RNN have the vanishing gradients and exploding gradient problems bescause of activation fucntions.

seq2seq models can not process a lenthy input sequences.

seq2seq models ahve a single attension mechanism.
even though its giving correctly answers but still we can not process a input as a whole sentences







